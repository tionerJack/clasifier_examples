{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 09:24:53.950795: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-30 09:24:54.025044: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-30 09:24:54.025089: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-30 09:24:54.025139: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-30 09:24:54.040335: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-30 09:24:54.041027: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-30 09:24:55.853928: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "import os \n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\"\n",
    "\n",
    "tmpDirectory = os.getcwd() +\"/tmp\"\n",
    "\n",
    "if not os.path.exists(tmpDirectory):\n",
    "    os.makedirs(tmpDirectory)\n",
    "\n",
    "filename = tmpDirectory+\"/cats_and_dogs_filtered.zip\"\n",
    "urllib.request.urlretrieve(url,filename)\n",
    "\n",
    "zipRef = zipfile.ZipFile(filename,\"r\")\n",
    "zipRef.extractall(tmpDirectory)\n",
    "zipRef.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat.967.jpg', 'cat.42.jpg', 'cat.81.jpg', 'cat.983.jpg', 'cat.601.jpg', 'cat.358.jpg', 'cat.109.jpg', 'cat.637.jpg', 'cat.427.jpg', 'cat.818.jpg']\n",
      "['dog.330.jpg', 'dog.261.jpg', 'dog.253.jpg', 'dog.404.jpg', 'dog.960.jpg', 'dog.758.jpg', 'dog.904.jpg', 'dog.146.jpg', 'dog.414.jpg', 'dog.236.jpg']\n"
     ]
    }
   ],
   "source": [
    "baseDir = os.path.join(tmpDirectory,\"cats_and_dogs_filtered\")\n",
    "\n",
    "trainDir = os.path.join(baseDir,\"train\")\n",
    "validationDir = os.path.join(baseDir,\"validation\")\n",
    "\n",
    "trainCatsDir = os.path.join(trainDir,\"cats\")\n",
    "trainDogsDir = os.path.join(trainDir,\"dogs\")\n",
    "\n",
    "validationCatsDir = os.path.join(validationDir,\"cats\")\n",
    "validationDogsDir = os.path.join(validationDir,\"dogs\")\n",
    "\n",
    "trainCatNames = os.listdir(trainCatsDir)\n",
    "trainDogNames = os.listdir(trainDogsDir)\n",
    "\n",
    "print(trainCatNames[:10])\n",
    "print(trainDogNames[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18496)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               9470464   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9494561 (36.22 MB)\n",
      "Trainable params: 9494561 (36.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(16,(3,3),activation=\"relu\", input_shape=(150,150,3) ),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation=\"relu\", input_shape=(150,150,3) ),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(64,(3,3),activation=\"relu\", input_shape=(150,150,3) ),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512,activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.)\n",
    "train_generation = train_datagen.flow_from_directory(trainDir,batch_size=20,class_mode=\"binary\",target_size=(150,150))\n",
    "validation_generation = test_datagen.flow_from_directory(validationDir,batch_size=20,class_mode=\"binary\",target_size=(150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 - 38s - loss: 0.7289 - accuracy: 0.5400 - val_loss: 0.6413 - val_accuracy: 0.6030 - 38s/epoch - 382ms/step\n",
      "Epoch 2/15\n",
      "100/100 - 40s - loss: 0.6252 - accuracy: 0.6455 - val_loss: 0.5974 - val_accuracy: 0.6750 - 40s/epoch - 405ms/step\n",
      "Epoch 3/15\n",
      "100/100 - 44s - loss: 0.5879 - accuracy: 0.6900 - val_loss: 0.5791 - val_accuracy: 0.6840 - 44s/epoch - 437ms/step\n",
      "Epoch 4/15\n",
      "100/100 - 41s - loss: 0.5523 - accuracy: 0.7105 - val_loss: 0.5712 - val_accuracy: 0.7060 - 41s/epoch - 406ms/step\n",
      "Epoch 5/15\n",
      "100/100 - 41s - loss: 0.5025 - accuracy: 0.7600 - val_loss: 0.6008 - val_accuracy: 0.6890 - 41s/epoch - 409ms/step\n",
      "Epoch 6/15\n",
      "100/100 - 40s - loss: 0.4467 - accuracy: 0.7805 - val_loss: 0.6059 - val_accuracy: 0.7150 - 40s/epoch - 398ms/step\n",
      "Epoch 7/15\n",
      "100/100 - 43s - loss: 0.4048 - accuracy: 0.8130 - val_loss: 0.5932 - val_accuracy: 0.7100 - 43s/epoch - 432ms/step\n",
      "Epoch 8/15\n",
      "100/100 - 42s - loss: 0.3461 - accuracy: 0.8455 - val_loss: 0.6799 - val_accuracy: 0.7100 - 42s/epoch - 416ms/step\n",
      "Epoch 9/15\n",
      "100/100 - 45s - loss: 0.2812 - accuracy: 0.8850 - val_loss: 0.7129 - val_accuracy: 0.7220 - 45s/epoch - 451ms/step\n",
      "Epoch 10/15\n",
      "100/100 - 43s - loss: 0.2075 - accuracy: 0.9165 - val_loss: 0.8097 - val_accuracy: 0.7170 - 43s/epoch - 428ms/step\n",
      "Epoch 11/15\n",
      "100/100 - 41s - loss: 0.1603 - accuracy: 0.9400 - val_loss: 0.8187 - val_accuracy: 0.7150 - 41s/epoch - 407ms/step\n",
      "Epoch 12/15\n",
      "100/100 - 39s - loss: 0.0931 - accuracy: 0.9680 - val_loss: 1.0010 - val_accuracy: 0.7200 - 39s/epoch - 386ms/step\n",
      "Epoch 13/15\n",
      "100/100 - 43s - loss: 0.1104 - accuracy: 0.9710 - val_loss: 1.1527 - val_accuracy: 0.7160 - 43s/epoch - 433ms/step\n",
      "Epoch 14/15\n",
      "100/100 - 37s - loss: 0.0535 - accuracy: 0.9845 - val_loss: 1.1110 - val_accuracy: 0.7290 - 37s/epoch - 373ms/step\n",
      "Epoch 15/15\n",
      "100/100 - 37s - loss: 0.0595 - accuracy: 0.9810 - val_loss: 1.4019 - val_accuracy: 0.7200 - 37s/epoch - 367ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generation,validation_data=validation_generation,steps_per_epoch=100,epochs=15,validation_steps=50,verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
